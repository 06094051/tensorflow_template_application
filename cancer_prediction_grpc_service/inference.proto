// Protobuf definition of generic model inference server.

syntax = "proto3";

import "tensorflow/core/framework/tensor.proto";

package tensorflow.serving;

message InferenceRequest {
  //map<string, TensorProto> inputs = 1;
  string data = 1;
}

message InferenceResponse {
  //map<string, TensorProto> outputs = 1;
  string data = 1;
};

service InferenceService {
  rpc DoInference(InferenceRequest) returns (InferenceResponse);
}
